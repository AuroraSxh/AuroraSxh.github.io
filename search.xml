<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>python_project(3)</title>
    <url>/2020/05/30/python-project-3/</url>
    <content><![CDATA[<h1 id="python大作业"><a href="#python大作业" class="headerlink" title="python大作业"></a>python大作业</h1><h2 id="新冠肺炎相关B站视频爬取及评论分析"><a href="#新冠肺炎相关B站视频爬取及评论分析" class="headerlink" title="新冠肺炎相关B站视频爬取及评论分析"></a>新冠肺炎相关B站视频爬取及评论分析</h2><h3 id="PART-Ⅲ"><a href="#PART-Ⅲ" class="headerlink" title="PART Ⅲ"></a>PART Ⅲ</h3><a id="more"></a>
<h4 id="LDA分析"><a href="#LDA分析" class="headerlink" title="LDA分析"></a>LDA分析</h4><p>LDA是一种文档主题生成模型，包含词、主题和文档三层结构。</p>
<ol>
<li>主题模型在自然语言处理等领域是用来在一系列文档中发现抽象主题的一种统计模型。判断两个文档相似性的传统方法是通过查看两个文档共同出现的单词的多少，如TF（词频）、TF-IDF（词频—逆向文档频率）等，这种方法没有考虑文字背后的语义关联，例如，两个文档共同出现的单词很少甚至没有，但两个文档是相似的，因此在判断文档相似性时，需要使用主题模型进行语义分析并判断文档相似性。如果一篇文档有多个主题，则一些特定的可代表不同主题的词语就会反复出现，此时，运用主题模型，能够发现文本中使用词语的规律，并且把规律相似的文本联系到一起，以寻求非结构化的文本集中的有用信息。例如，在美的电热水器的商品评论文本数据中，代表电热水器特征的词语如“安装”“出水量”“服务”等会频繁地出现在评论中，运用主题模型，把热水器代表性特征相关的情感描述性词语与对应特征的词语联系起来，从而深入了解用户对电热水器的关注点及用户对于某一特征的情感倾向</li>
</ol>
<ol start="2">
<li>LDA主题模型潜在狄利克雷分配，即LDA模型（Latent Dirichlet Allocation，LDA）是由Blei等人在2003年提出的生成式主题模型。所谓生成模型，就是说，我们认为一篇文章的每个词都是通过“以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语”这样一个过程得到。文档到主题服从多项式分布，主题到词服从多项式分布。LDA模型也被称为3层贝叶斯概率模型，包含文档（d）、主题（z）、词（w）3层结构，能够有效对文本进行建模，和传统的空间向量模型（VSM）相比，增加了概率的信息。通过LDA主题模型，能够挖掘数据集中的潜在主题，进而分析数据集的集中关注点及其相关特征词。LDA模型采用词袋模型（Bag of Words，BOW）将每一篇文档视为一个词频向量，从而将文本信息转化为易于建模的数字信息。定义词表大小为L，一个L维向量（1，0，0，…，0，0）表示一个词。由N个词构成的评论记为d=（w1，w2，…，wN）。假设某一商品的评论集D由M篇评论构成，记为D=（d1，d2，…，dM）。M篇评论分布着K个主题，记为Zi=（i=1，2，…，K）。记a和b为狄利克雷函数的先验参数，q为主题在文档中的多项分布的参数，其服从超参数为a的Dirichlet先验分布，f为词在主题中的多项分布的参数，其服从超参数b的Dirichlet先验分布。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> corpora, models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入情感分析后的数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">"./results1.csv"</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">posdata = data[data[<span class="string">'content_type'</span>] == <span class="number">1</span>]</span><br><span class="line">negdata = data[data[<span class="string">'content_type'</span>] == <span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立词典</span></span><br><span class="line">pos_dict = corpora.Dictionary([[i] <span class="keyword">for</span> i <span class="keyword">in</span> posdata[<span class="string">'word'</span>]])  <span class="comment"># 正面</span></span><br><span class="line">neg_dict = corpora.Dictionary([[i] <span class="keyword">for</span> i <span class="keyword">in</span> negdata[<span class="string">'word'</span>]])  <span class="comment"># 负面</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立语料库</span></span><br><span class="line">pos_corpus = [pos_dict.doc2bow(j) <span class="keyword">for</span> j <span class="keyword">in</span> [[i] <span class="keyword">for</span> i <span class="keyword">in</span> posdata[<span class="string">'word'</span>]]]  <span class="comment"># 正面</span></span><br><span class="line">neg_corpus = [neg_dict.doc2bow(j) <span class="keyword">for</span> j <span class="keyword">in</span> [[i] <span class="keyword">for</span> i <span class="keyword">in</span> negdata[<span class="string">'word'</span>]]]   <span class="comment"># 负面</span></span><br></pre></td></tr></table></figure>

<h4 id="主题数寻优"><a href="#主题数寻优" class="headerlink" title="主题数寻优"></a>主题数寻优</h4><p>基于相似度的自适应最优LDA模型选择方法，确定主题数并进行主题分析。实验证明该方法可以在不需要人工调试主题数目的情况下，用相对少的迭代找到最优的主题结构。</p>
<p>具体步骤如下：</p>
<ol>
<li>取初始主题数k值，得到初始模型，计算各主题之间的相似度（平均余弦距离）。</li>
<li>增加或减少k值，重新训练模型，再次计算各主题之间的相似度。</li>
<li>重复步骤2直到得到最优k值。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 主题数寻优</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lda_k</span><span class="params">(x_corpus, x_dict)</span>:</span>  </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化平均余弦相似度</span></span><br><span class="line">    mean_similarity = []</span><br><span class="line">    mean_similarity.append(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 循环生成主题并计算主题间相似度</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">2</span>,<span class="number">11</span>):</span><br><span class="line">        <span class="comment"># LDA模型训练</span></span><br><span class="line">        lda = models.LdaModel(x_corpus, num_topics = i, id2word = x_dict)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> np.arange(i):</span><br><span class="line">            term = lda.show_topics(num_words = <span class="number">50</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 提取各主题词</span></span><br><span class="line">        top_word = []</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> np.arange(i):</span><br><span class="line">            top_word.append([<span class="string">''</span>.join(re.findall(<span class="string">'"(.*)"'</span>,i)) \</span><br><span class="line">                             <span class="keyword">for</span> i <span class="keyword">in</span> term[k][<span class="number">1</span>].split(<span class="string">'+'</span>)])  <span class="comment"># 列出所有词</span></span><br><span class="line">           </span><br><span class="line">        <span class="comment"># 构造词频向量</span></span><br><span class="line">        word = sum(top_word,[])  <span class="comment"># 列出所有的词   </span></span><br><span class="line">        unique_word = set(word)  <span class="comment"># 去除重复的词</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构造主题词列表，行表示主题号，列表示各主题词</span></span><br><span class="line">        mat = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> np.arange(i):</span><br><span class="line">            top_w = top_word[j]</span><br><span class="line">            mat.append(tuple([top_w.count(k) <span class="keyword">for</span> k <span class="keyword">in</span> unique_word]))  </span><br><span class="line">            </span><br><span class="line">        p = list(itertools.permutations(list(np.arange(i)),<span class="number">2</span>))</span><br><span class="line">        l = len(p)</span><br><span class="line">        top_similarity = [<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> np.arange(l):</span><br><span class="line">            vector1 = mat[p[w][<span class="number">0</span>]]</span><br><span class="line">            vector2 = mat[p[w][<span class="number">1</span>]]</span><br><span class="line">            top_similarity.append(cos(vector1, vector2))</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 计算平均余弦相似度</span></span><br><span class="line">        mean_similarity.append(sum(top_similarity)/l)</span><br><span class="line">    <span class="keyword">return</span>(mean_similarity)</span><br><span class="line"></span><br><span class="line">pos_k = lda_k(pos_corpus, pos_dict)</span><br><span class="line">neg_k = lda_k(neg_corpus, neg_dict)</span><br><span class="line"></span><br><span class="line">font = FontProperties(size=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'KaiTi'</span>] <span class="comment"># 指定默认字体</span></span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span> <span class="comment"># 解决保存图像是负号'-'显示为方块的问题</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">211</span>)</span><br><span class="line">ax1.plot(pos_k)</span><br><span class="line">ax1.set_xlabel(<span class="string">'正面评论LDA主题数寻优'</span>, fontproperties=font)</span><br><span class="line"></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">212</span>)</span><br><span class="line">ax2.plot(neg_k)</span><br><span class="line">ax2.set_xlabel(<span class="string">'负面评论LDA主题数寻优'</span>, fontproperties=font)</span><br></pre></td></tr></table></figure>
<p>得到如图所示的结果：<br><img src="https://i.loli.net/2020/05/30/QWDiz9lpAw6Vats.png" alt="QGQ_I_WWI11_RU27P665AIP.png"></p>
<h4 id="评价主题分析结果"><a href="#评价主题分析结果" class="headerlink" title="评价主题分析结果"></a>评价主题分析结果</h4><p>根据主题数寻优结果，使用Python的Gensim模块对正面评论数据和负面评论数据分别构建LDA主题模型，设置主题数为3，经过LDA主题分析后，每个主题下生成10个最有可能出现的词语以及相应的概率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pos_lda = models.LdaModel(pos_corpus, num_topics = <span class="number">3</span>, id2word = pos_dict)  </span><br><span class="line">neg_lda = models.LdaModel(neg_corpus, num_topics = <span class="number">3</span>, id2word = neg_dict)</span><br><span class="line"></span><br><span class="line">pos_lda.print_topics(num_words = <span class="number">10</span>)</span><br><span class="line">neg_lda.print_topics(num_words = <span class="number">10</span>)</span><br><span class="line"><span class="keyword">import</span> pyLDAvis</span><br><span class="line"><span class="keyword">from</span> pyLDAvis <span class="keyword">import</span> gensim</span><br><span class="line"></span><br><span class="line">vis = pyLDAvis.gensim.prepare(pos_lda,pos_corpus,pos_dict)</span><br><span class="line"><span class="comment"># 需要的三个参数都可以从硬盘读取的，前面已经存储下来了</span></span><br><span class="line">print(<span class="string">'done'</span>)</span><br><span class="line"><span class="comment"># 在浏览器中心打开一个界面</span></span><br><span class="line">pyLDAvis.show(vis)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在notebook的output cell中显示</span></span><br><span class="line"><span class="comment">#pyLDAvis.display(vis)</span></span><br></pre></td></tr></table></figure>
<p>针对负面评论的分析和上面步骤一致：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vis = pyLDAvis.gensim.prepare(neg_lda,neg_corpus,neg_dict)</span><br><span class="line"><span class="comment"># 需要的三个参数都可以从硬盘读取的，前面已经存储下来了</span></span><br><span class="line">print(<span class="string">'done'</span>)</span><br><span class="line"><span class="comment"># 在浏览器中心打开一个界面</span></span><br><span class="line">pyLDAvis.show(vis)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在notebook的output cell中显示</span></span><br><span class="line"><span class="comment">#pyLDAvis.display(vis)</span></span><br></pre></td></tr></table></figure>
<p>结果如下图所示。<br><img src="https://i.loli.net/2020/05/30/T3yFIjs5MVU7aJv.png" alt="NI2LLLZ_Y_@A4QF@XDY9_FB.png"></p>
<p>可以发现，出现了一些误被分词的流行词如“川建国”等。这个问题在于<a href="https://aurorasxh.github.io/2020/05/30/python-project-2/" target="_blank" rel="noopener">python大作业partⅡ</a>中的<code>jiaba</code>分词过程中的误差。由此也可判单<code>jiaba</code>分词对于流行词与部分过于口语化的词的分词效果的不足。</p>
<p>接下来还有语义情感的进一步分析。</p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python_project(2)</title>
    <url>/2020/05/30/python-project-2/</url>
    <content><![CDATA[<h1 id="python大作业"><a href="#python大作业" class="headerlink" title="python大作业"></a>python大作业</h1><h2 id="新冠肺炎相关B站视频爬取及评论分析"><a href="#新冠肺炎相关B站视频爬取及评论分析" class="headerlink" title="新冠肺炎相关B站视频爬取及评论分析"></a>新冠肺炎相关B站视频爬取及评论分析</h2><h3 id="PART-Ⅱ"><a href="#PART-Ⅱ" class="headerlink" title="PART Ⅱ"></a>PART Ⅱ</h3><a id="more"></a>

<h4 id="视频评论的爬取"><a href="#视频评论的爬取" class="headerlink" title="视频评论的爬取"></a>视频评论的爬取</h4><p>我们调用了B站视频评论的<a href="https://api.bilibili.com/x/v2/reply?jsonp=jsonp&pn=1&type=1&oid=84850049&sort=2" target="_blank" rel="noopener">API</a>进行爬取，本来想爬取全部评论的，后来考虑到电脑运算能力的问题，所以选取了前150页的评论。在爬取过程中，出现了<code>TypeError</code>报错，检查发现从API中读取的json文件中有部分<code>item</code>是空的，因此报错。于是采用<code>try...except</code>结构进行规避。爬取部分代码如下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_comments</span><span class="params">(path,cmt_lst)</span>:</span></span><br><span class="line">    </span><br><span class="line">    data=&#123;<span class="string">'cmt'</span>:cmt_lst&#125;</span><br><span class="line">    df=pd.DataFrame(data)</span><br><span class="line">    df.to_csv(path,encoding=<span class="string">'utf_8_sig'</span>,index=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_comments</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    api=<span class="string">'https://api.bilibili.com/x/v2/reply?jsonp=jsonp&amp;pn=&#123;&#125;&amp;type=1&amp;oid=&#123;&#125;&amp;sort=2'</span> <span class="comment">#0为评论页数，1为av号</span></span><br><span class="line">    video_info=pd.read_csv(<span class="string">'video_info_100.csv'</span>)</span><br><span class="line">    oid_list=video_info[<span class="string">'av_oid'</span>].tolist()</span><br><span class="line">  </span><br><span class="line">    headers=&#123;<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36'</span>&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> oid <span class="keyword">in</span> oid_list:</span><br><span class="line">        print(oid)</span><br><span class="line">        comments=[]</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">150</span>):</span><br><span class="line">            API=api.format(num+<span class="number">1</span>,oid)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                r = requests.get(API,headers=headers)</span><br><span class="line">                <span class="comment">#print(r.status_code)</span></span><br><span class="line">                r_json=r.json()</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="keyword">for</span> item <span class="keyword">in</span> r_json[<span class="string">'data'</span>][<span class="string">'replies'</span>]:</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment">#print(item['content']['message'])</span></span><br><span class="line">                        comments.append(item[<span class="string">'content'</span>][<span class="string">'message'</span>])</span><br><span class="line">                <span class="keyword">except</span> TypeError:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">            <span class="keyword">except</span> requests.exceptions.RequestException <span class="keyword">as</span> err:</span><br><span class="line">                print(<span class="string">'err'</span>)</span><br><span class="line"></span><br><span class="line">        cmt_lst=comments</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        file_name=<span class="string">'&#123;&#125;_comments.csv'</span>.format(oid)</span><br><span class="line">        path=<span class="string">'./video_comments/'</span>+file_name</span><br><span class="line">        <span class="keyword">with</span> open(path,<span class="string">'w'</span>) <span class="keyword">as</span> file:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        save_comments(path,cmt_lst)</span><br><span class="line">        print(oid,<span class="string">':done'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    bt = time.time()</span><br><span class="line">    get_comments()</span><br><span class="line">    et = time.time()</span><br><span class="line">    runtime = et - bt</span><br><span class="line">    print(<span class="string">'程序运行时间为：'</span>,runtime)</span><br></pre></td></tr></table></figure>

<h4 id="视频评论的情感分析"><a href="#视频评论的情感分析" class="headerlink" title="视频评论的情感分析"></a>视频评论的情感分析</h4><p>在这里我们通过<code>SnowNlp</code>包进行评论的语义情感分析。</p>
<h5 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h5><p>考虑到B站评论与微博评论的相似性，我们采用了12万条微博评论（正面评论与负面评论各6万条）进行训练，训练结果储存为<code>new_sentiment.marshal.3</code>文件 。代码如下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> snownlp <span class="keyword">import</span> SnowNLP</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"><span class="keyword">from</span> snownlp <span class="keyword">import</span> sentiment</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用微博评论（正面负面各6万条共12万条）训练snownlp</span></span><br><span class="line">pd_all = pd.read_csv(<span class="string">'weibo_senti_100k.csv'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pd_all[pd_all.label == <span class="number">1</span>][<span class="string">'review'</span>].tolist():</span><br><span class="line">    f = open(<span class="string">'pos.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    f.write(i + <span class="string">'\n'</span>)</span><br><span class="line">    f.close()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> pd_all[pd_all.label == <span class="number">0</span>][<span class="string">'review'</span>].tolist():</span><br><span class="line">    f = open(<span class="string">'neg.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    f.write(j + <span class="string">'\n'</span>)</span><br><span class="line">    f.close()</span><br><span class="line">sentiment.train(<span class="string">'1_neg.txt'</span>,<span class="string">'1_pos.txt'</span>)</span><br><span class="line">sentiment.save(<span class="string">'new_sentiment.marshal'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#视频标题评分</span></span><br><span class="line">file = pd.read_csv(<span class="string">'video_info_100.csv'</span>)</span><br><span class="line">video_info_df = pd.DataFrame(file)</span><br><span class="line">title_list = video_info_df[<span class="string">'name'</span>].tolist()</span><br><span class="line">title_scores = []</span><br><span class="line"><span class="keyword">for</span> titles <span class="keyword">in</span> title_list:</span><br><span class="line">    <span class="keyword">if</span> <span class="string">""</span>.join(jieba.analyse.textrank(titles)) != <span class="string">''</span>:</span><br><span class="line">        scores = SnowNLP(<span class="string">""</span>.join(jieba.analyse.textrank(titles)))</span><br><span class="line">        title_scores.append((scores.sentiments))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        scores = SnowNLP(titles)</span><br><span class="line">        title_scores.append((scores.sentiments))</span><br><span class="line"></span><br><span class="line">video_info_df[<span class="string">'title_scores'</span>] = title_scores</span><br><span class="line">video_info_df.to_csv(<span class="string">"./video_info_100.csv"</span>,encoding = <span class="string">'utf_8_sig'</span>,index = <span class="literal">False</span>)</span><br><span class="line">print(<span class="string">'work done'</span>)</span><br></pre></td></tr></table></figure>

<h5 id="B站视频评论情感分析"><a href="#B站视频评论情感分析" class="headerlink" title="B站视频评论情感分析"></a>B站视频评论情感分析</h5><p>然后即可运用训练好的模型对评论进行语义情感分析，并根据得分进行分级。-1为负面，0为中性，1为正面。得到结果储存为csv文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> snownlp <span class="keyword">import</span> SnowNLP</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line">    file = pd.read_csv('video_info_100.csv')</span><br><span class="line">    video_info_df = pd.DataFrame(file)</span><br><span class="line">    <span class="keyword">for</span> av <span class="keyword">in</span> video_info_df[<span class="string">'av_oid'</span>].tolist():</span><br><span class="line">        file_name = <span class="string">'./video_comments/&#123;&#125;_comments.csv'</span>.format(av)</span><br><span class="line">        <span class="comment">#print(file_name)</span></span><br><span class="line">        comments_file = pd.read_csv(file_name)</span><br><span class="line">        comments_df = pd.DataFrame(comments_file)</span><br><span class="line">        comments_scores = []</span><br><span class="line">        levels = []</span><br><span class="line">        <span class="keyword">for</span> comments <span class="keyword">in</span> comments_df[<span class="string">'cmt'</span>].tolist():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">""</span>.join(jieba.analyse.textrank(comments)) != <span class="string">''</span>:</span><br><span class="line">                scores = SnowNLP(<span class="string">""</span>.join(jieba.analyse.textrank(comments)))</span><br><span class="line">                comments_scores.append((scores.sentiments))</span><br><span class="line">                <span class="keyword">if</span> float(scores.sentiments) &gt;= <span class="number">0.65</span>:</span><br><span class="line">                    levels.append(<span class="string">'1'</span>)</span><br><span class="line">                <span class="keyword">elif</span> float(scores.sentiments) &gt;= <span class="number">0.35</span> <span class="keyword">and</span> float(scores.sentiments) &lt; <span class="number">0.65</span>:</span><br><span class="line">                    levels.append(<span class="string">'0'</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    levels.append(<span class="string">'-1'</span>)                </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                scores = SnowNLP(comments)</span><br><span class="line">                comments_scores.append((scores.sentiments))</span><br><span class="line">                <span class="keyword">if</span> float(scores.sentiments) &gt;= <span class="number">0.6</span>:</span><br><span class="line">                    levels.append(<span class="string">'1'</span>)</span><br><span class="line">                <span class="keyword">elif</span> float(scores.sentiments) &gt;= <span class="number">0.4</span> <span class="keyword">and</span> float(scores.sentiments) &lt; <span class="number">0.6</span>:</span><br><span class="line">                    levels.append(<span class="string">'0'</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    levels.append(<span class="string">'-1'</span>)</span><br><span class="line">        comments_df[<span class="string">'comments_scores'</span>] = comments_scores</span><br><span class="line">        comments_df[<span class="string">'levels'</span>] = levels</span><br><span class="line">        comments_df.to_csv(file_name,encoding = <span class="string">'utf_8_sig'</span>,index = <span class="literal">False</span>)</span><br><span class="line">        print(av,<span class="string">":done"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h4 id="词频分析"><a href="#词频分析" class="headerlink" title="词频分析"></a>词频分析</h4><p>得到了所有的评论后，进行了词频分析。运用<code>jiaba</code>包进行分词和词性分析，绘制词云，并根据名词词频运用pyecharts包进行南丁格尔玫瑰图的绘制。<br>代码如下。<br>首先载入所需第三方库，并将所有评论汇集到<code>comments.csv</code>文件中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> jieba.posseg <span class="keyword">as</span> psg</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Pie</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> ThemeType</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> CurrentConfig, NotebookType</span><br><span class="line">CurrentConfig.NOTEBOOK_TYPE = NotebookType.JUPYTER_LAB</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_comments</span><span class="params">(path)</span></span></span><br><span class="line">for maindir, subdir, file_name_list in os.walk(path):</span><br><span class="line">    file1 = pd.read_csv(path + <span class="string">'/'</span> + file_name_list[<span class="number">0</span>])</span><br><span class="line">    comments_info_df1 = pd.DataFrame(file1)</span><br><span class="line">    comments_info_df1.to_csv(<span class="string">'./comments.csv'</span>,index = <span class="literal">False</span>,encoding = <span class="string">'utf_8_sig'</span>)</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> file_name_list[<span class="number">1</span>:]:        </span><br><span class="line">        file = pd.read_csv(path + <span class="string">'/'</span> + filename)</span><br><span class="line">        comments_info_df = pd.DataFrame(file)</span><br><span class="line">        comments_info_df.to_csv(<span class="string">'./comments.csv'</span>,mode = <span class="string">'a'</span>,header = <span class="literal">False</span>,index = <span class="literal">False</span>,encoding = <span class="string">'utf_8_sig'</span>)</span><br></pre></td></tr></table></figure>
<p>一共获得了25万余条评论。<br>然后，运用<code>jiaba</code>包进行分词。因为评论条数很多，所以程序运行起来很慢，花了约六小时才完成分词。分词结果存入<code>results1.csv</code>文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_words</span><span class="params">(file,result_file_path)</span>:</span>    </span><br><span class="line">    c_df = pd.DataFrame(file)</span><br><span class="line">    reviews = c_df[[<span class="string">'cmt'</span>,<span class="string">'levels'</span>]]</span><br><span class="line">    content = c_df[<span class="string">'cmt'</span>]</span><br><span class="line">    strinfo = re.compile(<span class="string">'[0-9a-zA-Z]|热词系列|纳豆|奶奶|豆奶|'</span>)</span><br><span class="line">    content = content.apply(<span class="keyword">lambda</span> x:strinfo.sub(<span class="string">''</span>,x))</span><br><span class="line">    worker = <span class="keyword">lambda</span> s:[(x.word,x.flag) <span class="keyword">for</span> x <span class="keyword">in</span> psg.cut(s)]</span><br><span class="line">    seg_word = content.apply(worker)</span><br><span class="line">    seg_word.head()</span><br><span class="line"></span><br><span class="line">    n_word = seg_word.apply(<span class="keyword">lambda</span> x: len(x))  <span class="comment"># 每一评论中词的个数</span></span><br><span class="line">    n_content = [[x+<span class="number">1</span>]*y <span class="keyword">for</span> x,y <span class="keyword">in</span> zip(list(seg_word.index), list(n_word))]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将嵌套的列表展开，作为词所在评论的id</span></span><br><span class="line">    index_content = sum(n_content,[])</span><br><span class="line"></span><br><span class="line">    seg_word = sum(seg_word, [])</span><br><span class="line">    <span class="comment"># 词</span></span><br><span class="line">    word = [x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> seg_word]</span><br><span class="line">    <span class="comment"># 词性</span></span><br><span class="line">    nature = [x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> seg_word]</span><br><span class="line"></span><br><span class="line">    content_type = [[x]*y <span class="keyword">for</span> x,y <span class="keyword">in</span> zip(list(reviews[<span class="string">'levels'</span>]), list(n_word))]</span><br><span class="line">    <span class="comment"># 评论类型</span></span><br><span class="line">    content_type = sum(content_type, [])</span><br><span class="line"></span><br><span class="line">    result = pd.DataFrame(&#123;<span class="string">"index_content"</span>:index_content, </span><br><span class="line">                           <span class="string">"word"</span>:word,</span><br><span class="line">                           <span class="string">"nature"</span>:nature,</span><br><span class="line">                           <span class="string">"content_type"</span>:content_type&#125;)</span><br><span class="line">    result.head()</span><br><span class="line"></span><br><span class="line">    result = result[result[<span class="string">'nature'</span>] != <span class="string">'x'</span>]  <span class="comment"># x表示标点符号</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除停用词</span></span><br><span class="line">    stop_path = open(<span class="string">"./stoplist.txt"</span>, <span class="string">'r'</span>,encoding=<span class="string">'UTF-8'</span>)</span><br><span class="line">    stop = stop_path.readlines()</span><br><span class="line">    stop = [x.replace(<span class="string">'\n'</span>, <span class="string">''</span>) <span class="keyword">for</span> x <span class="keyword">in</span> stop]</span><br><span class="line">    word = list(set(word) - set(stop))</span><br><span class="line">    result = result[result[<span class="string">'word'</span>].isin(word)]</span><br><span class="line">    result.head()</span><br><span class="line"></span><br><span class="line">    n_word = list(result.groupby(by = [<span class="string">'index_content'</span>])[<span class="string">'index_content'</span>].count())</span><br><span class="line">    index_word = [list(np.arange(<span class="number">0</span>, y)) <span class="keyword">for</span> y <span class="keyword">in</span> n_word]</span><br><span class="line">    <span class="comment"># 词语在该评论的位置</span></span><br><span class="line">    index_word = sum(index_word, [])</span><br><span class="line">    <span class="comment"># 合并评论id</span></span><br><span class="line">    result[<span class="string">'index_word'</span>] = index_word</span><br><span class="line">    result.head()</span><br><span class="line"></span><br><span class="line">    ind = result[[<span class="string">'n'</span> <span class="keyword">in</span> x <span class="keyword">for</span> x <span class="keyword">in</span> result[<span class="string">'nature'</span>]]][<span class="string">'index_content'</span>].unique()</span><br><span class="line">    result = result[[x <span class="keyword">in</span> ind <span class="keyword">for</span> x <span class="keyword">in</span> result[<span class="string">'index_content'</span>]]]</span><br><span class="line">    result.head()</span><br><span class="line">    result.to_csv(result_file_path,index = <span class="number">0</span>,encoding = <span class="string">'utf_8_sig'</span>)</span><br></pre></td></tr></table></figure>

<p>分词完成后，取词频等就顺理成章了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pick_frequency</span><span class="params">(raw_file_path)</span>:</span></span><br><span class="line">    result = pd.read_csv(raw_file_path)</span><br><span class="line">    frequencies = result.groupby(<span class="string">'word'</span>)[<span class="string">'word'</span>].count()</span><br><span class="line">    frequencies = frequencies.sort_values(ascending = <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> frequencies</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pick_top10_noun</span><span class="params">(raw_file_path)</span></span></span><br><span class="line">    result = pd.read_csv(raw_file_path)</span><br><span class="line">    result_n = result[(result[<span class="string">'nature'</span>] == <span class="string">'ns'</span>) | ( result[<span class="string">'nature'</span>] == <span class="string">'vn'</span> ) | (result[<span class="string">'nature'</span>] == <span class="string">'n'</span> )| ( result[<span class="string">'nature'</span>] == <span class="string">'nr'</span> )| ( result[<span class="string">'nature'</span>] == <span class="string">'nrt'</span> )]</span><br><span class="line">    frequencies = result_n.groupby(<span class="string">'word'</span>)[<span class="string">'word'</span>].count()</span><br><span class="line">    frequencies = frequencies.sort_values(ascending = <span class="literal">False</span>)</span><br><span class="line">    top_10 = frequencies[<span class="number">0</span>:<span class="number">10</span>]</span><br><span class="line">    noun = top_10.index.tolist()</span><br><span class="line">    num = list(top_10)</span><br><span class="line">    nnlist = [list(z) <span class="keyword">for</span> z <span class="keyword">in</span> zip(noun,num)]</span><br><span class="line">    <span class="keyword">return</span> nnlist</span><br></pre></td></tr></table></figure>

<p>运用<code>wordcloud</code>包进行词云绘制。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_word_cloud</span><span class="params">(raw_file_path,raw_image_path,font_path_,save_image_path)</span>:</span></span><br><span class="line">    result = pd.read_csv(raw_file_path)</span><br><span class="line"></span><br><span class="line">    frequencies = result.groupby(<span class="string">'word'</span>)[<span class="string">'word'</span>].count()</span><br><span class="line">    frequencies = frequencies.sort_values(ascending = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    backgroud_Image=plt.imread(raw_image_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自己上传中文字体到kesci</span></span><br><span class="line">    <span class="comment">#font_path = './Deng.ttf'</span></span><br><span class="line">    wordcloud = WordCloud(font_path=font_path_, <span class="comment"># 设置字体，不设置就会出现乱码</span></span><br><span class="line">                          max_words = <span class="number">1000</span>,</span><br><span class="line">                          margin = <span class="number">1</span>,</span><br><span class="line">                          scale = <span class="number">10</span>,</span><br><span class="line">                          background_color=<span class="string">'white'</span>,</span><br><span class="line">                          mask = backgroud_Image)<span class="comment"># 词云形状</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    my_wordcloud = wordcloud.fit_words(frequencies)</span><br><span class="line">    plt.imshow(my_wordcloud)</span><br><span class="line">    plt.axis(<span class="string">'off'</span>) </span><br><span class="line">    plt.savefig(save_image_path,dpi = <span class="number">600</span>)</span><br></pre></td></tr></table></figure>

<p>运用<code>pyecharts</code>包绘制南丁格尔玫瑰图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_ndge_plot</span><span class="params">(word_list,color_series,final_path)</span>:</span>    </span><br><span class="line">    <span class="comment"># 实例化Pie类</span></span><br><span class="line">    pie1 = Pie(init_opts=opts.InitOpts(width=<span class="string">'1350px'</span>, height=<span class="string">'750px'</span>,theme=ThemeType.WESTEROS))</span><br><span class="line">    <span class="comment"># 设置颜色</span></span><br><span class="line">    pie1.set_colors(color_series)</span><br><span class="line"></span><br><span class="line">    pie1.add(<span class="string">""</span>, word_list,</span><br><span class="line">            radius=[<span class="string">"20%"</span>, <span class="string">"100%"</span>],</span><br><span class="line">            center=[<span class="string">"30%"</span>, <span class="string">"65%"</span>],</span><br><span class="line">            rosetype=<span class="string">"area"</span></span><br><span class="line">            ) </span><br><span class="line"></span><br><span class="line">    pie1.set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">'test'</span>),</span><br><span class="line">                         legend_opts=opts.LegendOpts(is_show=<span class="literal">False</span>),</span><br><span class="line">                         toolbox_opts=opts.ToolboxOpts())</span><br><span class="line">    <span class="comment"># 设置系列配置项</span></span><br><span class="line">    pie1.set_series_opts(label_opts=opts.LabelOpts(is_show=<span class="literal">True</span>, position=<span class="string">"inside"</span>, font_size=<span class="number">12</span>,formatter=<span class="string">"&#123;b&#125;:&#123;c&#125;"</span>, font_style=<span class="string">"italic"</span>,font_weight=<span class="string">"bold"</span>, font_family=<span class="string">"Microsoft YaHei"</span>),)</span><br><span class="line">    <span class="comment"># 生成html文档</span></span><br><span class="line">    pie1.render(final_path)</span><br></pre></td></tr></table></figure>
<p>主程序调用函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    file = pd.read_csv(<span class="string">'./comments.csv'</span>)</span><br><span class="line">    color_series = [<span class="string">'#C9DA36'</span>,<span class="string">'#9ECB3C'</span>,<span class="string">'#6DBC49'</span>,</span><br><span class="line">                        <span class="string">'#37B44E'</span>,<span class="string">'#3DBA78'</span>,<span class="string">'#14ADCF'</span>,<span class="string">'#209AC9'</span>,<span class="string">'#1E91CA'</span>,</span><br><span class="line">                        <span class="string">'#2C6BA0'</span>,<span class="string">'#2B55A1'</span>,<span class="string">'#2D3D8E'</span>,<span class="string">'#44388E'</span>,<span class="string">'#6A368B'</span>,</span><br><span class="line">                        <span class="string">'#7D3990'</span>,<span class="string">'#A63F98'</span>,<span class="string">'#C31C88'</span>,<span class="string">'#D52178'</span>,<span class="string">'#D5225B'</span>,</span><br><span class="line">                        <span class="string">'#D02C2A'</span>,<span class="string">'#D44C2D'</span>,<span class="string">'#F57A34'</span>,<span class="string">'#FA8F2F'</span>,<span class="string">'#D99D21'</span>,</span><br><span class="line">                        <span class="string">'#CF7B25'</span>,<span class="string">'#CF7B25'</span>,<span class="string">'#CF7B25'</span>]</span><br><span class="line">    get_comments(path = <span class="string">'./video_comments'</span>)</span><br><span class="line">    split_words(file = file ,result_file_path = <span class="string">'./results1.csv'</span>)</span><br><span class="line">    draw_word_cloud(raw_file_path = <span class="string">'./results1.csv'</span>,raw_image_path = <span class="string">'./unlogo.jpg'</span>,font_path_= <span class="string">'./Deng.ttf'</span>,save_image_path = <span class="string">'wordcloud2.png'</span>)</span><br><span class="line">    </span><br><span class="line">    noun_list = pick_top10_noun(raw_file_path = <span class="string">'./results1.csv'</span>)</span><br><span class="line">    draw_ndge_plot(word_list = noun_list,color_series = color_series,final_path = <span class="string">'./figures/test2.html'</span>)</span><br></pre></td></tr></table></figure>
<p>词云绘制结果如下。<br><img src="https://i.loli.net/2020/05/30/njce8LlwYpdMCZv.png" alt="wordcloud2.png"></p>
<p>下面是南丁格尔玫瑰图的展示。其展现了评论出现次数最高的10个名词。</p>
<html><head>
    <meta charset="UTF-8">
    <title>Awesome-pyecharts</title>
  <meta name="generator" content="hexo-theme-yilia-plus">
            <script type="text/javascript" src="https://assets.pyecharts.org/assets/echarts.min.js"></script>
        <script type="text/javascript" src="https://assets.pyecharts.org/assets/themes/westeros.js"></script>

<link rel="alternate" href="/atom.xml" title="Aurora Song" type="application/atom+xml">
</head>
<body>
    <div id="1800ef3832aa42f5990496eb6d041184" class="chart-container" style="width: 700px; height: 700px; -webkit-tap-highlight-color: transparent; user-select: none; position: relative;" _echarts_instance_="ec_1590812655099"><div style="position: relative; overflow: hidden; width: 700px; height: 700px; padding: 0px; margin: 0px; border-width: 0px; cursor: default;"><canvas data-zr-dom-id="zr_0" width="875" height="875" style="position: absolute; left: 0px; top: 0px; width: 700px; height: 700px; user-select: none; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); padding: 0px; margin: 0px; border-width: 0px;"></canvas></div><div style="position: absolute; display: none; border-style: solid; white-space: nowrap; z-index: 9999999; transition: left 0.4s cubic-bezier(0.23, 1, 0.32, 1) 0s, top 0.4s cubic-bezier(0.23, 1, 0.32, 1) 0s; background-color: rgba(50, 50, 50, 0.7); border-width: 0px; border-color: rgb(51, 51, 51); border-radius: 4px; color: rgb(255, 255, 255); font: 14px / 21px &quot;Microsoft YaHei&quot;; padding: 5px; left: 258px; top: 200px; pointer-events: none;"><span style="display:inline-block;margin-right:5px;border-radius:10px;width:10px;height:10px;background-color:#C9DA36;"></span>中国: 28,723</div></div>
    <script>
        var chart_1800ef3832aa42f5990496eb6d041184 = echarts.init(
            document.getElementById('1800ef3832aa42f5990496eb6d041184'), 'westeros', {renderer: 'canvas'});
        var option_1800ef3832aa42f5990496eb6d041184 = {
    "animation": true,
    "animationThreshold": 2000,
    "animationDuration": 1000,
    "animationEasing": "cubicOut",
    "animationDelay": 0,
    "animationDurationUpdate": 300,
    "animationEasingUpdate": "cubicOut",
    "animationDelayUpdate": 0,
    "series": [
        {
            "type": "pie",
            "clockwise": true,
            "data": [
                {
                    "name": "\u4e2d\u56fd",
                    "value": 28723
                },
                {
                    "name": "\u7f8e\u56fd",
                    "value": 25589
                },
                {
                    "name": "\u6b66\u6c49",
                    "value": 19119
                },
                {
                    "name": "\u53e3\u7f69",
                    "value": 12343
                },
                {
                    "name": "\u56fd\u5bb6",
                    "value": 10781
                },
                {
                    "name": "\u75ab\u60c5",
                    "value": 9605
                },
                {
                    "name": "\u75c5\u6bd2",
                    "value": 9429
                },
                {
                    "name": "\u89c6\u9891",
                    "value": 7407
                },
                {
                    "name": "\u65e5\u672c",
                    "value": 6788
                },
                {
                    "name": "\u7279\u6717\u666e",
                    "value": 4714
                }
            ],
            "radius": [
                "20%",
                "100%"
            ],
            "center": [
                "30%",
                "65%"
            ],
            "roseType": "area",
            "label": {
                "show": true,
                "position": "inside",
                "margin": 8,
                "fontSize": 12,
                "fontStyle": "italic",
                "fontWeight": "bold",
                "fontFamily": "Microsoft YaHei",
                "formatter": "{b}:{c}"
            },
            "rippleEffect": {
                "show": true,
                "brushType": "stroke",
                "scale": 2.5,
                "period": 4
            }
        }
    ],
    "legend": [
        {
            "data": [
                "\u4e2d\u56fd",
                "\u7f8e\u56fd",
                "\u6b66\u6c49",
                "\u53e3\u7f69",
                "\u56fd\u5bb6",
                "\u75ab\u60c5",
                "\u75c5\u6bd2",
                "\u89c6\u9891",
                "\u65e5\u672c",
                "\u7279\u6717\u666e"
            ],
            "selected": {},
            "show": false,
            "padding": 5,
            "itemGap": 10,
            "itemWidth": 25,
            "itemHeight": 14
        }
    ],
    "tooltip": {
        "show": true,
        "trigger": "item",
        "triggerOn": "mousemove|click",
        "axisPointer": {
            "type": "line"
        },
        "textStyle": {
            "fontSize": 14
        },
        "borderWidth": 0
    },
    "color": [
        "#C9DA36",
        "#9ECB3C",
        "#6DBC49",
        "#37B44E",
        "#3DBA78",
        "#14ADCF",
        "#209AC9",
        "#1E91CA",
        "#2C6BA0",
        "#2B55A1",
        "#2D3D8E",
        "#44388E",
        "#6A368B",
        "#7D3990",
        "#A63F98",
        "#C31C88",
        "#D52178",
        "#D5225B",
        "#D02C2A",
        "#D44C2D",
        "#F57A34",
        "#FA8F2F",
        "#D99D21",
        "#CF7B25",
        "#CF7B25",
        "#CF7B25"
    ],
    "title": [
        {
            "text": "test",
            "padding": 5,
            "itemGap": 10
        }
    ],
    "toolbox": {
        "show": true,
        "orient": "horizontal",
        "itemSize": 15,
        "itemGap": 10,
        "left": "80%",
        "feature": {
            "saveAsImage": {
                "type": "png",
                "backgroundColor": "auto",
                "connectedBackgroundColor": "#fff",
                "show": true,
                "title": "\u4fdd\u5b58\u4e3a\u56fe\u7247",
                "pixelRatio": 1
            },
            "restore": {
                "show": true,
                "title": "\u8fd8\u539f"
            },
            "dataView": {
                "show": true,
                "title": "\u6570\u636e\u89c6\u56fe",
                "readOnly": false,
                "lang": [
                    "\u6570\u636e\u89c6\u56fe",
                    "\u5173\u95ed",
                    "\u5237\u65b0"
                ],
                "backgroundColor": "#fff",
                "textareaColor": "#fff",
                "textareaBorderColor": "#333",
                "textColor": "#000",
                "buttonColor": "#c23531",
                "buttonTextColor": "#fff"
            },
            "dataZoom": {
                "show": true,
                "title": {
                    "zoom": "\u533a\u57df\u7f29\u653e",
                    "back": "\u533a\u57df\u7f29\u653e\u8fd8\u539f"
                },
                "icon": {}
            },
            "magicType": {
                "show": true,
                "type": [
                    "line",
                    "bar",
                    "stack",
                    "tiled"
                ],
                "title": {
                    "line": "\u5207\u6362\u4e3a\u6298\u7ebf\u56fe",
                    "bar": "\u5207\u6362\u4e3a\u67f1\u72b6\u56fe",
                    "stack": "\u5207\u6362\u4e3a\u5806\u53e0",
                    "tiled": "\u5207\u6362\u4e3a\u5e73\u94fa"
                },
                "icon": {}
            },
            "brush": {
                "icon": {},
                "title": {
                    "rect": "\u77e9\u5f62\u9009\u62e9",
                    "polygon": "\u5708\u9009",
                    "lineX": "\u6a2a\u5411\u9009\u62e9",
                    "lineY": "\u7eb5\u5411\u9009\u62e9",
                    "keep": "\u4fdd\u6301\u9009\u62e9",
                    "clear": "\u6e05\u9664\u9009\u62e9"
                }
            }
        }
    }
};
        chart_1800ef3832aa42f5990496eb6d041184.setOption(option_1800ef3832aa42f5990496eb6d041184);
    </script>


</body></html>

<p>至此词频分析及初阶情感分析告一段落。还需进行更深入的情感分析。</p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>520</title>
    <url>/2020/05/20/520xixixi/</url>
    <content><![CDATA[<h1 id="520啦"><a href="#520啦" class="headerlink" title="520啦"></a>520啦</h1><iframe name="music" src="https://www.epidemicsound.com/track/uUfcfLBI8d
" marginwidth="1px" marginheight="10px" width="100%" height="300px" frameborder="1" 　scrolling="yes">
</iframe>



<p>记录宝宝的一段话：<br>我真的好喜欢你的温柔呜呜。记得寒假辅导员让我们写上学期的期末总结，我在里面写道：“谢谢南大让我遇到了一群温暖的人。”在写那个的时候，不知道为什么，我第一反应是想到了你。总之，在和你一天一天的相处中，我越来越感觉到你的可爱。可爱，就是值得被爱的意思，就是…越来越喜欢你的意思！真的真的好喜欢小涵。我太期待和你在夏末秋初的仙林的见面啦！</p>
<p>永远珍惜！</p>
]]></content>
      <categories>
        <category>小朋友和我</category>
      </categories>
      <tags>
        <tag>yxx&amp;sxh</tag>
      </tags>
  </entry>
  <entry>
    <title>python_project(1)</title>
    <url>/2020/05/20/python-project-1/</url>
    <content><![CDATA[<h1 id="python大作业"><a href="#python大作业" class="headerlink" title="python大作业"></a>python大作业</h1><h2 id="新冠肺炎相关B站视频爬取及评论分析"><a href="#新冠肺炎相关B站视频爬取及评论分析" class="headerlink" title="新冠肺炎相关B站视频爬取及评论分析"></a>新冠肺炎相关B站视频爬取及评论分析</h2><h3 id="PART-Ⅰ"><a href="#PART-Ⅰ" class="headerlink" title="PART Ⅰ"></a>PART Ⅰ</h3><a id="more"></a>
<h4 id="爬取新冠肺炎相关视频信息"><a href="#爬取新冠肺炎相关视频信息" class="headerlink" title="爬取新冠肺炎相关视频信息"></a>爬取新冠肺炎相关视频信息</h4><p>python大作业，我们小组计划搜集新冠肺炎相关BiliBili视频的评论，并针对评论进行中文语义情感分析、词频分析等基础分析。</p>
<p>为了完成这项工作，我们首先需要爬取新冠肺炎相关的视频信息，包括视频标题、视频链接。</p>
<p>首先进入搜索页面，键入“新冠肺炎”。为了减小后续工作量，我们在网页中直接勾选“最多点击”，使结果按照点击量排序。得到搜索结果如下图：</p>
<p><img src="https://i.loli.net/2020/05/20/ECGm875vOazdIxZ.png" alt="M_`5_WS_4DL_88V_QGW6K`N.png"></p>
<p>观察网站源代码，可见红色方框内的代码包含了我们所需要的视频标题与视频链接的信息。<br><img src="https://i.loli.net/2020/05/20/e7duBP1ShUM9mpy.png" alt="RZQVTH_45__C158@UIB_9_7.png"></p>
<p>有了这些条件，就可以开始进行爬取了。</p>
<h5 id="依赖包"><a href="#依赖包" class="headerlink" title="依赖包"></a>依赖包</h5><p>首先载入爬取所需要的包。因为B站有一定的反爬措施，所以需要<code>fake_useragent</code>来提供多个请求头信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> requests <span class="keyword">import</span> get</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br></pre></td></tr></table></figure>
<h5 id="爬取"><a href="#爬取" class="headerlink" title="爬取"></a>爬取</h5><p>因为搜索结果不止一页，因此定义函数<code>get_url_list</code>来获取每一页的url，并返回为一个列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_url_list</span><span class="params">(page)</span>:</span></span><br><span class="line">    <span class="comment">#page = int(input('输入页码：'))</span></span><br><span class="line">    url_list = []</span><br><span class="line">    j = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> j &lt;= page:</span><br><span class="line">        url = <span class="string">"https://search.bilibili.com/video?keyword=%E6%96%B0%E5%86%A0%E8%82%BA%E7%82%8E&amp;order=click&amp;duration=0&amp;tids_1=0&amp;page="</span> + str(j)</span><br><span class="line">        url_list.append(url)</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> url_list</span><br></pre></td></tr></table></figure>
<p>获取了所有url的列表后，定义函数<code>open_url</code>和<code>get_Video</code>对网页进行爬取，并用<code>lxml</code>包对网页进行解析，获得所需视频信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">open_url</span><span class="params">(url)</span>:</span></span><br><span class="line">    ua = UserAgent()</span><br><span class="line">    random_header = ua.chrome</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>: random_header</span><br><span class="line">        &#125;</span><br><span class="line">    res = get(url, headers = headers)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_Video</span><span class="params">(res)</span>:</span></span><br><span class="line">    html = etree.HTML(res.text)</span><br><span class="line">    name = html.xpath(<span class="string">'//*[@class="video-item matrix"]/a/@title'</span>)</span><br><span class="line">    href = html.xpath(<span class="string">'//*[@class="video-item matrix"]/a/@href'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(href)):</span><br><span class="line">        href[i]=<span class="string">'https:'</span> + href[i]</span><br><span class="line">    <span class="keyword">return</span> name, href</span><br></pre></td></tr></table></figure>

<h5 id="集成"><a href="#集成" class="headerlink" title="集成"></a>集成</h5><p>最后定义<code>main()</code>主函数，调用上述函数进行爬取，并将结果写入csv文件中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    page = int(input(<span class="string">'输入页码：'</span>))</span><br><span class="line">    <span class="comment">#url = 'https://search.bilibili.com/video?keyword=%E6%96%B0%E5%86%A0%E8%82%BA%E7%82%8E&amp;order=click&amp;duration=0&amp;tids_1=0&amp;page=&#123;&#125;'.format(str(j))</span></span><br><span class="line">    url_list = get_url_list(page)     </span><br><span class="line">    name_list = []</span><br><span class="line">    href_list = []</span><br><span class="line">    <span class="keyword">for</span> urls <span class="keyword">in</span> url_list:</span><br><span class="line">        res = open_url(urls)</span><br><span class="line">        name, href = get_Video(res)</span><br><span class="line">        name_list.extend(name)</span><br><span class="line">        href_list.extend(href)</span><br><span class="line">    video_info_df = pd.DataFrame(&#123;<span class="string">'name'</span>:name_list, <span class="string">'href'</span>:href_list&#125;)</span><br><span class="line">    video_info_df.to_csv(<span class="string">'./video_info.csv'</span>,encoding = <span class="string">'utf_8_sig'</span>,index = <span class="number">0</span>)    <span class="comment">#写入csv文件,不保留行索引</span></span><br></pre></td></tr></table></figure>
<p>最后，调用主函数，爬取完成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h5 id="将bv号转换为av号"><a href="#将bv号转换为av号" class="headerlink" title="将bv号转换为av号"></a>将bv号转换为av号</h5><p>为了减轻工作量，我们采用调用B站API的形式爬取视频评论，而API中oid部分对应的是视频的av编号，而爬取的视频链接中呈现的是bv编号，因此，需要对其进行转换。<br>参考了教程：<a href="https://www.bilibili.com/video/BV1R7411y7kw" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1R7411y7kw</a><br>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bv_to_av</span><span class="params">(bv_num)</span>:</span></span><br><span class="line">    BvNo1 = bv_num[<span class="number">0</span>][<span class="number">2</span>:]</span><br><span class="line">    <span class="comment">#print(BvNo1)</span></span><br><span class="line">    keys = &#123;</span><br><span class="line">        <span class="string">'1'</span>:<span class="string">'13'</span>, <span class="string">'2'</span>:<span class="string">'12'</span>, <span class="string">'3'</span>:<span class="string">'46'</span>, <span class="string">'4'</span>:<span class="string">'31'</span>, <span class="string">'5'</span>:<span class="string">'43'</span>, <span class="string">'6'</span>:<span class="string">'18'</span>, <span class="string">'7'</span>:<span class="string">'40'</span>, <span class="string">'8'</span>:<span class="string">'28'</span>, <span class="string">'9'</span>:<span class="string">'5'</span>,</span><br><span class="line">        <span class="string">'A'</span>:<span class="string">'54'</span>, <span class="string">'B'</span>:<span class="string">'20'</span>, <span class="string">'C'</span>:<span class="string">'15'</span>, <span class="string">'D'</span>:<span class="string">'8'</span>, <span class="string">'E'</span>:<span class="string">'39'</span>, <span class="string">'F'</span>:<span class="string">'57'</span>, <span class="string">'G'</span>:<span class="string">'45'</span>, <span class="string">'H'</span>:<span class="string">'36'</span>, <span class="string">'J'</span>:<span class="string">'38'</span>, <span class="string">'K'</span>:<span class="string">'51'</span>, <span class="string">'L'</span>:<span class="string">'42'</span>, <span class="string">'M'</span>:<span class="string">'49'</span>, <span class="string">'N'</span>:<span class="string">'52'</span>, <span class="string">'P'</span>:<span class="string">'53'</span>, <span class="string">'Q'</span>:<span class="string">'7'</span>, <span class="string">'R'</span>:<span class="string">'4'</span>, <span class="string">'S'</span>:<span class="string">'9'</span>, <span class="string">'T'</span>:<span class="string">'50'</span>, <span class="string">'U'</span>:<span class="string">'10'</span>, <span class="string">'V'</span>:<span class="string">'44'</span>, <span class="string">'W'</span>:<span class="string">'34'</span>, <span class="string">'X'</span>:<span class="string">'6'</span>, <span class="string">'Y'</span>:<span class="string">'25'</span>, <span class="string">'Z'</span>:<span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'a'</span>: <span class="string">'26'</span>, <span class="string">'b'</span>: <span class="string">'29'</span>, <span class="string">'c'</span>: <span class="string">'56'</span>, <span class="string">'d'</span>: <span class="string">'3'</span>, <span class="string">'e'</span>: <span class="string">'24'</span>, <span class="string">'f'</span>: <span class="string">'0'</span>, <span class="string">'g'</span>: <span class="string">'47'</span>, <span class="string">'h'</span>: <span class="string">'27'</span>, <span class="string">'i'</span>: <span class="string">'22'</span>, <span class="string">'j'</span>: <span class="string">'41'</span>, <span class="string">'k'</span>: <span class="string">'16'</span>, <span class="string">'m'</span>: <span class="string">'11'</span>, <span class="string">'n'</span>: <span class="string">'37'</span>, <span class="string">'o'</span>: <span class="string">'2'</span>,</span><br><span class="line">        <span class="string">'p'</span>: <span class="string">'35'</span>, <span class="string">'q'</span>: <span class="string">'21'</span>, <span class="string">'r'</span>: <span class="string">'17'</span>, <span class="string">'s'</span>: <span class="string">'33'</span>, <span class="string">'t'</span>: <span class="string">'30'</span>, <span class="string">'u'</span>: <span class="string">'48'</span>, <span class="string">'v'</span>: <span class="string">'23'</span>, <span class="string">'w'</span>: <span class="string">'55'</span>, <span class="string">'x'</span>: <span class="string">'32'</span>, <span class="string">'y'</span>: <span class="string">'14'</span>,<span class="string">'z'</span>:<span class="string">'19'</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 2. 将key对应的value存入一个列表</span></span><br><span class="line">    BvNo2 = []</span><br><span class="line">    <span class="keyword">for</span> index, ch <span class="keyword">in</span> enumerate(BvNo1):</span><br><span class="line">        BvNo2.append(int(str(keys[ch])))</span><br><span class="line">    <span class="comment"># 3. 对列表中不同位置的数进行*58的x次方的操作</span></span><br><span class="line">    BvNo2[<span class="number">0</span>] = int(BvNo2[<span class="number">0</span>] * math.pow(<span class="number">58</span>, <span class="number">6</span>));</span><br><span class="line">    BvNo2[<span class="number">1</span>] = int(BvNo2[<span class="number">1</span>] * math.pow(<span class="number">58</span>, <span class="number">2</span>));</span><br><span class="line">    BvNo2[<span class="number">2</span>] = int(BvNo2[<span class="number">2</span>] * math.pow(<span class="number">58</span>, <span class="number">4</span>));</span><br><span class="line">    BvNo2[<span class="number">3</span>] = int(BvNo2[<span class="number">3</span>] * math.pow(<span class="number">58</span>, <span class="number">8</span>));</span><br><span class="line">    BvNo2[<span class="number">4</span>] = int(BvNo2[<span class="number">4</span>] * math.pow(<span class="number">58</span>, <span class="number">5</span>));</span><br><span class="line">    BvNo2[<span class="number">5</span>] = int(BvNo2[<span class="number">5</span>] * math.pow(<span class="number">58</span>, <span class="number">9</span>));</span><br><span class="line">    BvNo2[<span class="number">6</span>] = int(BvNo2[<span class="number">6</span>] * math.pow(<span class="number">58</span>, <span class="number">3</span>));</span><br><span class="line">    BvNo2[<span class="number">7</span>] = int(BvNo2[<span class="number">7</span>] * math.pow(<span class="number">58</span>, <span class="number">7</span>));</span><br><span class="line">    BvNo2[<span class="number">8</span>] = int(BvNo2[<span class="number">8</span>] * math.pow(<span class="number">58</span>, <span class="number">1</span>));</span><br><span class="line">    BvNo2[<span class="number">9</span>] = int(BvNo2[<span class="number">9</span>] * math.pow(<span class="number">58</span>, <span class="number">0</span>));</span><br><span class="line">    <span class="comment"># 4.求出这10个数的合</span></span><br><span class="line">    sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> BvNo2:</span><br><span class="line">        sum += i</span><br><span class="line">    <span class="comment"># 5. 将和减去100618342136696320</span></span><br><span class="line">    sum -= <span class="number">100618342136696320</span></span><br><span class="line">    <span class="comment"># 6. 将sum 与177451812进行异或</span></span><br><span class="line">    temp = <span class="number">177451812</span></span><br><span class="line">    av = sum ^ temp</span><br><span class="line">    <span class="keyword">return</span> av</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    file = pd.read_csv(<span class="string">'video_info.csv'</span>)</span><br><span class="line">    video_info_df = pd.DataFrame(file)</span><br><span class="line"></span><br><span class="line">    av_list = [] </span><br><span class="line">    <span class="keyword">for</span> urls <span class="keyword">in</span> video_info_df[<span class="string">'href'</span>]:</span><br><span class="line">        bv = re.compile(<span class="string">'(BV.*)\?'</span>)</span><br><span class="line">        bv_num = bv.findall(urls)</span><br><span class="line">        av = bv_to_av(bv_num)</span><br><span class="line">        av_list.append(str(av))</span><br><span class="line">    <span class="comment">#print(av_list)</span></span><br><span class="line">    video_info_df[<span class="string">'av_oid'</span>] = av_list</span><br><span class="line">    video_info_df.to_csv(<span class="string">"./video_info.csv"</span>,encoding = <span class="string">'utf_8_sig'</span>,index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>剩余任务还有，视频评论的爬取，评论词频分析、中文语义分析。</p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Summary of the WIKI of 2017-CPU-iGEM-Team</title>
    <url>/2020/04/09/Summary-of-the-WIKI-of-2017-CPU-iGEM-Team/</url>
    <content><![CDATA[<p>对中国药科大学2017年的iGEM项目进行介绍，这是<a href="http://2017.igem.org/Team:CPU_CHINA" target="_blank" rel="noopener">团队Wiki链接</a>。</p>
<a id="more"></a>

<h1 id="人类工程化的抗自身免疫疾病调节性T细胞系统"><a href="#人类工程化的抗自身免疫疾病调节性T细胞系统" class="headerlink" title="人类工程化的抗自身免疫疾病调节性T细胞系统"></a>人类工程化的抗自身免疫疾病调节性T细胞系统</h1><hr>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p><strong>类风湿 免疫抑制与平衡 嵌合抗原受体改造</strong></p>
<hr>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>类风湿性关节炎伴随着局部免疫失衡，表现在Th17细胞过度活跃，IL6、IL17等促炎因子分泌提升，但Treg等抑炎细胞功能被抑制。</p>
<p>CPU的团队设计了一个<strong>SynNotch</strong>系统，该系统包含修饰的Notch蛋白使得该蛋白能够在存在<strong>IL17A</strong>的炎症条件下<strong>特异性激活USP7的基因表达</strong>。USP7蛋白可以导致FOXP3蛋白去泛素化，从而通过保护FOXP3<strong>免受泛素化降解</strong>来增强FOXP3蛋白在炎症环境中的稳定性。因此，Treg细胞可以维持其免疫抑制功能。同时，我们设计了一个CAR系统，该系统可使Treg细胞靶向<strong>CD20 + B淋巴细胞</strong>，从而专门发挥免疫抑制功能，从而发挥抗炎作用。</p>
<hr>
<h2 id="原理图"><a href="#原理图" class="headerlink" title="原理图"></a>原理图</h2><p>SynNotch接收来自Th17细胞分泌的IL17-A，剪切下Gal4-vp64复合体，Gal4-vp64进入细胞核促进USP7的转录，USP7保护FOXP3不被泛素化降解。同时CAR系统识别CD20+ B淋巴细胞（依靠B淋巴细胞<strong>特异性表达CD20</strong>)，通过常规的共刺激序列4-1BB增强Treg功能。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">酵母Gal4-UAS系统：Gal4蛋白可以特异性识别其基因组中的UAS序列。</span><br><span class="line"></span><br><span class="line">人工转录因子vp64:vp64是一种反式作用因子。在本项目中被连接在Gal4蛋白上，当Gal4蛋白与UAS序列结合后，vp64能促进跟</span><br><span class="line">的在UAS序列之后的USP7的转录。</span><br><span class="line"></span><br><span class="line">Notch系统：Notch蛋白是跨膜蛋白，可分为三个结构域：细胞外结构域，跨膜结构域和细胞内结构域。在其细胞内结构域内有一</span><br><span class="line">个切割位点，Notch蛋白将在刺激下被切割，从膜上释放其C端肽与下游蛋白结合并进行信号转导。</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/04/09/CZQFdXoWKqUJah9.png" alt="示意图1"></p>
<p><img src="https://i.loli.net/2020/04/10/QxHMbCBotukg91V.png" alt="示意图2"></p>
<hr>
<h2 id="质粒载体系统"><a href="#质粒载体系统" class="headerlink" title="质粒载体系统"></a>质粒载体系统</h2><h3 id="SynNotch"><a href="#SynNotch" class="headerlink" title="SynNotch"></a><a href="http://parts.igem.org/Part:BBa_K2506001" target="_blank" rel="noopener">SynNotch</a></h3><p>SynNotch是一种能够在炎症环境中<strong>特异性激活USP7基因</strong>的表达，从而通过稳定FOXP3蛋白来维持Treg细胞的活性的系统。其构建的质粒载体大小为10699bp。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">IL17RA:IL17的受体，能够特异性识别IL17；</span><br><span class="line"></span><br><span class="line">Notch1：Notch蛋白核心区，包括重复序列，异二聚化结构域和跨膜结构域。其在接受信号（本项目中为IL17)后被激活，对胞内末</span><br><span class="line">端蛋白序列进行切割；</span><br><span class="line"></span><br><span class="line">Gal4-vp64:如前所述。</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/04/09/riD2jtGZzV4N3X6.png" alt="质粒图谱1"></p>
<h3 id="UUpromU"><a href="#UUpromU" class="headerlink" title="UUpromU"></a><a href="http://parts.igem.org/Part:BBa_K2506004" target="_blank" rel="noopener">UUpromU</a></h3><p>UUpromU是专门为SynNotch系统能特异性表达目标基因设计的系统。</p>
<h4 id="pcDNA-3-1"><a href="#pcDNA-3-1" class="headerlink" title="pcDNA 3.1(+)"></a>pcDNA 3.1(+)</h4><p>全长7005bp。携带两个UAS序列、USP7的启动子序列及USP7基因序列。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">实际上该团队是将UUpromU序列放入pcDNA 3.1(+)质粒中的。</span><br><span class="line"></span><br><span class="line">UAS序列：与前述vp64结合，促进USP7的高表达；</span><br><span class="line"></span><br><span class="line">USP7：保护FOXP3不被泛素化降解，从而保证Treg细胞的抑制炎症的作用。</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/04/09/oOCJr1vHblnscRW.png" alt="质粒图谱2"></p>
<h3 id="CAR-Treg"><a href="#CAR-Treg" class="headerlink" title="CAR-Treg"></a><a href="http://parts.igem.org/Part:BBa_K2506002" target="_blank" rel="noopener">CAR-Treg</a></h3><p>CAR-CD20是使工程改造的T细胞能够特异性识别B淋巴细胞中的表面抗原CD20从而加强其抗炎功能的模块。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CD20-ScFv：CD20蛋白的单链抗体。由CD20单克隆抗体的可变区序列构建。用于准确识别并结合B淋巴细胞表面抗原CD20；</span><br><span class="line"></span><br><span class="line">C-Myc tag：与目的蛋白一起表达地蛋白标签，便于目的蛋白的表达、检测、示踪和纯化等；</span><br><span class="line"></span><br><span class="line">4-1BB：共刺激信号；</span><br><span class="line"></span><br><span class="line">CD3Z:刺激信号。与4-1BB一起促进信号的高水平传递，从而更强地激活Treg细胞；</span><br><span class="line"></span><br><span class="line">mCherry：荧光蛋白，便于基因表达的检测。</span><br></pre></td></tr></table></figure>
<p><img src="https://i.loli.net/2020/04/09/Dm3hWCpwzAyJObK.png" alt="质粒图谱3"></p>
<p><em>注：该项目组采用慢病毒和电转两种方式传递质粒，其实我没有很理解。电转质粒对细胞损伤大且入核率低，如何控制两种方式转染的细胞在相同环境下的目的基因表达量相似是一个值得思索的问题。</em></p>
<hr>
<h2 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h2><ul>
<li>考虑改造T细胞的生存期问题</li>
<li>考虑部分电转Treg细胞的转染效率问题</li>
<li>类风湿关节炎病人Th17浓度升高是广泛的，其血清Th17浓度也升高了，考虑到这点，如何限定该团队设计的Treg细胞的作用范围就值得思索了。如果在全身触发较大规模的免疫抑制效应，其后果将是可怕的。</li>
</ul>
<hr>
<h2 id="可借鉴之处"><a href="#可借鉴之处" class="headerlink" title="可借鉴之处"></a>可借鉴之处</h2><p>emmm似乎在实验设计和元件设计上没有什么值得借鉴的，他们的元件设计较为简单，没有复杂的逻辑电路，CMV启动子等也是比较常见的。还有一点让我奇怪的是他们的参考文献里由Tet-on系统但是他们的元件设计里没有体现，有点奇怪。</p>
<p>但是值得我们提起注意的是，我们要选择合适的靶点进行设计，同时选择合适的刺激因素，兼顾表达量与特异性。同时应当使用各种手段控制元件的作用范围。</p>
]]></content>
      <categories>
        <category>iGEM</category>
      </categories>
      <tags>
        <tag>Project Review</tag>
      </tags>
  </entry>
  <entry>
    <title>Tet-on System</title>
    <url>/2020/04/02/Tet-on-System/</url>
    <content><![CDATA[<h1 id="Tet-on诱导表达系统的介绍"><a href="#Tet-on诱导表达系统的介绍" class="headerlink" title="Tet-on诱导表达系统的介绍"></a>Tet-on诱导表达系统的介绍</h1><a id="more"></a>
<h2 id="Tet-on-四环素诱导表达系统"><a href="#Tet-on-四环素诱导表达系统" class="headerlink" title="Tet-on 四环素诱导表达系统"></a>Tet-on 四环素诱导表达系统</h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>Tet调控表达系统通过诱导药物（如Tet）改变调控蛋白的构象，从而达到调控目标蛋白表达的目的。</p>
<p>最初的Tet调控基因表达系统是以大肠杆菌Tn10转座子上Tet抗性操纵子为基础而建立的。Tet阻遏蛋白（Tet repressor protein, TetR）与Tet操纵子（Tet operator, TetO）能够特异性结合。当细胞内无Tet存在时，Tet会与TetO结合，从而阻断下游抗性基因表达；当有Tet存在时，Tet使TetR构象发生改变，导致TetR与TetO分离，使下游抗性基因得以表达，细菌从而获得耐药性。<br><img src="https://i.loli.net/2020/04/02/2r3b9Qky5NlGF7H.png" alt="原理图"></p>
<h3 id="Tet-on-调控系统"><a href="#Tet-on-调控系统" class="headerlink" title="Tet-on 调控系统"></a>Tet-on 调控系统</h3><p>利用TetR和TetO特异性结合的特点，多种类型的Tet调控系统逐渐发展起来。根据应用广泛的是Tet-on激活型系统。</p>
<p>Tet-on系统由调节表达载体和反应表达载体组成。</p>
<p>调节表达载体包含一个人巨细胞病毒早期启动子（PhCMV）和反义Tet转录活化因子（reverse tetracycline transcriptional activator，rtTA）。其中rtTA由反义TetR（reverse TetR, rTetR）和单纯疱疹病毒（HSV）VP16蛋白C端的一段转录激活区域融合而成。</p>
<p>反应表达载体由Tet应答元件（Tet-responsive element, TRE）、最小CMV启动子（minimal CMV promoter, PminCMV）及目的基因组成。其中TRE是7个重复的TetO序列。</p>
<p>由于PminCMV缺少增强子，因此rtTA未与TRE结合时，目的基因不表达；当rtTA与TRE结合时，VP16会使PminCMV活化从而使基因表达。</p>
<p>在Dox不存在时，rTetR不能与TRE结合，导致基因表达被抑制；而当Dox存在时，rTetR能与TRE结合，进而使得目的基因表达。<br><img src="https://i.loli.net/2020/04/02/eEwQj94MLPvRWpO.png" alt="Tet-on系统原理图"></p>
<p><em>当然还有Tet-off系统，原理相似，在此不多赘述</em></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Molin M, Shoshan MC, Ohman-Forslund K, Linder S, Akusjärvi G. Two novel adenovirus vector systems permitting regulated protein expression in gene transfer experiments. J Virol. 1998;72(10):8358–8361.</li>
<li>Freundlieb, S., Schirra‐Müller, C. and Bujard, H. (1999), A tetracycline controlled activation/repression system with increased potential for gene transfer into mammalian cells. J. Gene Med., 1: 4-12. doi:10.1002/(SICI)1521-2254(199901/02)1:1&lt;4::AID-JGM4&gt;3.0.CO;2-Y</li>
<li><a href="http://2013.igem.org/Team:Bielefeld_Germany/Biosafety/Biosafety_System_M" target="_blank" rel="noopener">http://2013.igem.org/Team:Bielefeld_Germany/Biosafety/Biosafety_System_M</a></li>
<li><a href="http://2013.igem.org/Team:SYSU-China/Project/Design" target="_blank" rel="noopener">http://2013.igem.org/Team:SYSU-China/Project/Design</a></li>
</ol>
]]></content>
      <categories>
        <category>iGEM</category>
      </categories>
      <tags>
        <tag>Gene Transport</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction to some lentiviral vectors</title>
    <url>/2020/04/02/Introduction-to-some-lentiviral-vectors/</url>
    <content><![CDATA[<p>两家公司的四环素诱导目的基因表达的慢病毒载体的介绍</p>
<a id="more"></a>
<h2 id="ViraPower™-HiPerform™-T‑REx™-Gateway™-Expression-System"><a href="#ViraPower™-HiPerform™-T‑REx™-Gateway™-Expression-System" class="headerlink" title="ViraPower™ HiPerform™ T‑REx™ Gateway™ Expression System"></a>ViraPower™ HiPerform™ T‑REx™ Gateway™ Expression System</h2><p><a href="https://www.thermofisher.com/order/catalog/product/A11141?SID=srch-srp-A11141#/A11141?SID=srch-srp-A11141" target="_blank" rel="noopener">产品网页链接看这里。</a><br>ViraPower™HiPerform™T-REx™Gateway®表达系统包括生成慢病毒所需的所有组件，包括载体试剂盒，293FT细胞系和支持试剂盒。它是一种五质粒慢病毒载体，能够在分裂或非分裂细胞系中构建稳定的<strong>四环素诱导</strong>的目标基因表达体系。</p>
<h3 id="主要特征"><a href="#主要特征" class="headerlink" title="主要特征"></a>主要特征</h3><ul>
<li>利用土拨鼠肝炎病毒的WPRE元件（土拨鼠转录后调控元件），增加了HIV-1整合酶基因的转基因表达和cPPT（中央多嘌呤区），增加了整合入宿主基因组的慢病毒的拷贝数，从而提高了病毒滴度。</li>
<li>由人巨细胞病毒（CMV）启动子和两个四环素操纵子（TetO2）组成的杂合启动子能够使得目的基因大量、稳定表达</li>
<li>采用弹性蛋白标记</li>
</ul>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ul>
<li>产生无复制能力的慢病毒，用于转染分裂和非分裂的哺乳动物细胞</li>
<li>使用Gateway®技术轻松进行基于基因重组的克隆</li>
<li>形成稳定的，长期的，通过四环素调节的基因表达</li>
<li>与传统的慢病毒表达系统相比，能产生更高的蛋白表达水平。</li>
</ul>
<h3 id="两个重要质粒"><a href="#两个重要质粒" class="headerlink" title="两个重要质粒"></a>两个重要质粒</h3><h4 id="pLenti6-3-TO-V5-DEST™"><a href="#pLenti6-3-TO-V5-DEST™" class="headerlink" title="pLenti6.3/TO/V5-DEST™"></a>pLenti6.3/TO/V5-DEST™</h4><p>该目的载体使用T‑REx™技术来进行四环素调节的目的基因表达。包括用于将表达构建体包装到病毒体中的元件，用于选择稳定转导的细胞系的杀稻瘟素抗性标记，同时利用HiperForm技术来增加病毒滴度和转基因表达。<br><img src="https://i.loli.net/2020/04/02/67xiqy1K4O53BAk.png" alt="pLenti6.3/TO/V5-DEST™载质粒"></p>
<h4 id="pLenti3-3-TR"><a href="#pLenti3-3-TR" class="headerlink" title="pLenti3.3/TR"></a>pLenti3.3/TR</h4><p>该阻遏质粒利用HiPerform™技术在CMV启动子的控制下组成型表达高水平的四环素（Tet）阻遏物；包括用于病毒包装的元件，用于选择稳定转导的细胞系的新霉素抗性标记。<br><img src="https://i.loli.net/2020/04/02/bE9I7UJl1SuZLht.png" alt="pLenti3.3/TR质粒"></p>
<h2 id="吉凯基因-TetIIP-Puromycin-表达系统"><a href="#吉凯基因-TetIIP-Puromycin-表达系统" class="headerlink" title="吉凯基因 TetIIP Puromycin 表达系统"></a>吉凯基因 TetIIP Puromycin 表达系统</h2><p><a href="http://www.taogene.com/emkt.htm#/PcMerchandises?id=%40%5B256%5D.%5B254%5D%230&categoryId=20" target="_blank" rel="noopener">产品链接看这里。</a><br>吉凯 Tet on 可诱导基因表达慢病毒产品感染目的细胞，可在目的细胞中获得可灵敏调控的目的基因表达，在细胞培养基中不含Dox（doxycycline，多西环素）时，目的基因本底表达量极低，加入Dox 后，目的基因诱导表达量极高。客户还可用此慢病毒产品感染目的细胞后，经过筛选获得可诱导表达的稳定细胞株。</p>
<p>诱导原理为：rtTA 是从大肠杆菌中改造得来的反式作用因子，其在 Dox 存在的情况下能够与正式作用元件 TRE（tetracycline response element）结合，进而促进下游基因转录，目的基因表达；而在不含 Dox 的情况下，trTA 从 TRE 上脱离，基因停止转录，目的基因停止表达</p>
<p>吉凯基因采用的是第三代的慢病毒载体系统。将目的基因插入过表达慢病毒载体后，通过包装获得的病毒颗粒成为过表达慢病毒产品，<strong>但该病毒仍然具有可能的潜在的生物学危险</strong>。吉凯基因建议不要使用编码已知或可能会致癌的基因的假型病毒。除非已经完全公认某个基因肯定没有致癌性，否则均不建议采用假型病毒进行生物学实验。</p>
<h3 id="优势-1"><a href="#优势-1" class="headerlink" title="优势"></a>优势</h3><ul>
<li>严格调控</li>
<li>反应迅速</li>
<li>蛋白表达量与加入诱导剂的浓度正相关，表达量可调控</li>
<li>特异性强，无副诱导</li>
<li>诱导剂容易获得且诱导浓度低</li>
</ul>
<h3 id="CV051载体质粒图谱"><a href="#CV051载体质粒图谱" class="headerlink" title="CV051载体质粒图谱"></a>CV051载体质粒图谱</h3><p><img src="https://i.loli.net/2020/04/02/iBW1VsULJnPdtv4.jpg" alt="载体质粒图谱"></p>
]]></content>
      <categories>
        <category>iGEM</category>
      </categories>
      <tags>
        <tag>Gene Transport</tag>
      </tags>
  </entry>
  <entry>
    <title>Movie Time!</title>
    <url>/2020/03/21/Movie-Time/</url>
    <content><![CDATA[<p>今天<strong>第一次</strong>和小朋友看了电影！电影名字是 <strong><em>Level 16</em></strong>。嘤电影有点吓人，但是小朋友超级好的！我被吓到的时候疯狂安慰我<del>有点不好意思的说哈哈哈一个男生吓成那样呜</del>。但还是很开心呀，只不过下次一定要换喜剧片哼。</p>
]]></content>
      <categories>
        <category>小朋友和我</category>
      </categories>
      <tags>
        <tag>yxx&amp;sxh</tag>
      </tags>
  </entry>
  <entry>
    <title>Lentivirus</title>
    <url>/2020/03/21/Lentivirus/</url>
    <content><![CDATA[<p>iGEM比赛我方队伍所需慢病毒基础知识</p>
<a id="more"></a>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="慢病毒载体系统"><a href="#慢病毒载体系统" class="headerlink" title="慢病毒载体系统"></a>慢病毒载体系统</h2><p>慢病毒载体系统是一种能非常高效的把外源基因稳定整合到哺乳动物细胞中的载体工具。除了常规质粒转染外，目前该系统也是把外源基因转入哺乳动物细胞的最常用方法之一。由于具有目的基因和启动子选择的灵活性以及转染细胞类型的广泛性两大特点，使得慢病毒载体系统成为倍受欢迎的外源基因表达系统。</p>
<p>慢病毒载体来源于人类免疫缺陷病毒HIV，属于逆转录病毒家族。野生型慢病毒基因组是由线性双正链RNA构成的。</p>
<p>慢病毒重组载体构建完成后与辅助质粒一起转染进入包装细胞。在包装细胞中，位于两个长末端重复序列（LTR）之间的DNA片段会被转录成RNA，由辅助质粒表达的病毒蛋白将其包装形成病毒颗粒。包装后的活体病毒将会被释放到上清液中，可以直接收集或进一步浓缩病毒转染靶细胞。</p>
<p>当病毒转导靶细胞时，释放到宿主细胞中的病毒RNA借助逆转录酶逆转录成双链DNA，然后随机整合进宿主细胞的基因组中。在病毒载体中，位于两个LTR的DNA片段和病毒基因组都会稳定整合到靶细胞的基因组中。</p>
<h2 id="慢病毒结构"><a href="#慢病毒结构" class="headerlink" title="慢病毒结构"></a>慢病毒结构</h2><p>病毒结构蛋白gag、pol和env。gag基因编码病毒的核心蛋白如核衣壳蛋白（p7）、内膜蛋白（p17）和衣壳蛋白（p24）；pol基因编码病毒复制相关的酶；env基因编码病毒包膜糖蛋白。</p>
<p>病毒调节蛋白rev,tat。rev主要参与蛋白调节的表达水平，tat参与蛋白转录的控制，与病毒的长末端重复序列（long terminal repeats, LTRS）结合后促进病毒的所有基因的转录。</p>
<p>四个辅助蛋白，即vif、vpr、vpu、nef，帮助病毒包装完成<br><img src="https://i.loli.net/2020/03/21/UYR6wkXyMfHFxDV.png" alt="慢病毒基因结构"></p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>源基因的稳定整合</li>
<li>滴度高</li>
<li>宿主范围广泛</li>
<li>基因拷贝数相对均一</li>
<li>安全性<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3></li>
<li>载体容量有限制：大概只有６－７kb的可用序列长度</li>
<li>技术比较复杂<h1 id="四质粒慢病毒载体系统"><a href="#四质粒慢病毒载体系统" class="headerlink" title="四质粒慢病毒载体系统"></a>四质粒慢病毒载体系统</h1>这是第三代慢病毒载体系统。顾名思义其包含了四个质粒序列。其可以将目标基因的<strong>cDNA</strong>序列转入靶细胞的基因组中。四质粒系统主要是：pGag/Pol、pRev、pVSV-G，此外，还有一个可以放置目的基因序列的载体。这个体系产生活性病毒的可能被大大降低。(5′端LTR被替换成了CMV，3′端LTR被换成了SV40 ployA 这两个都是可以增强表达，减低病毒对人体危害性)<br>如下是一家公司的<em>pLenti CMV GFP Hygro</em>核心质粒序列，<a href="https://www.addgene.org/17446/" target="_blank" rel="noopener">相关网址在这里</a>。<br><img src="https://i.loli.net/2020/03/21/g7iAKf1B3ljrCTP.png" alt="一个四质粒表达系统中的核心质粒（举个例子）"></li>
</ul>
<h1 id="小总结"><a href="#小总结" class="headerlink" title="小总结"></a>小总结</h1><p>至于我们实验中具体用要到的慢病毒载体，现在有几点是比较明确的。</p>
<ul>
<li>使用的是第三代四质粒慢病毒转染载体</li>
<li>核心质粒中整合进去的目的基因片段最好不超过6-7kb，否则会导致病毒滴度的下降</li>
<li>慢病毒一般需要BSL-2等级的实验室及相关受培训操作人员进行操作，所以我们应该只需要将质粒设计出来并验证。</li>
<li>在查阅文献时有发现肝脏特异性靶向的四环素介导的白蛋白启动子调控的慢病毒载体，<a href="http://www.cnki.com.cn/Article/CJFDTotal-DYJZ201908008.htm" target="_blank" rel="noopener">相关论文见此</a>。可供参考。</li>
</ul>
<h2 id="个人建议"><a href="#个人建议" class="headerlink" title="个人建议"></a>个人建议</h2><p>其实相对于设计质粒的工作来说，寻找合适的慢病毒载体工作非常简单。慢病毒载体的最核心部分其实是核心质粒的设计，对于四质粒转运系统来说似乎其他三个和慢病毒转染等相关的质粒差异并不是很大？虽然可以在关注慢病毒载体同时分一点心看一下脂质体载体和裸质粒，但既然我们是想做肝脏的长期给药系统的话，效率最高的似乎还是慢病毒转染。<br><del>淦 居然漏掉了第四代质粒</del></p>
]]></content>
      <categories>
        <category>iGEM</category>
      </categories>
      <tags>
        <tag>Gene Transport</tag>
      </tags>
  </entry>
  <entry>
    <title>First Step</title>
    <url>/2020/03/18/First-Step/</url>
    <content><![CDATA[<p>I love you three thousand.</p>
<a id="more"></a>
<h2 id="想法"><a href="#想法" class="headerlink" title="想法"></a>想法</h2><p>今天突发奇想，找到了以前搭着玩儿的小博客，正好可以用来记录两个人的一点一滴哈哈哈<del>说好打造成学习博客的呢</del>。</p>
<hr>
<h2 id="嘤嘤嘤"><a href="#嘤嘤嘤" class="headerlink" title="嘤嘤嘤"></a>嘤嘤嘤</h2><p>嘛3月15号在一起之后真的好激动啊哈哈哈哈<del>等了四个多小时隔壁还一直在敲墙真的紧张死了QAQ</del>。但是真的<strong>好开心啊！</strong></p>
<h2 id="一点小小的期待"><a href="#一点小小的期待" class="headerlink" title="一点小小的期待"></a>一点小小的期待</h2><p>唔，虽然我大概率要考研，考研时候可能真的很忙，但我还是会尽量陪着你的！医学院压力大需要多陪陪的！</p>
<h2 id="最后玩儿一点小花样"><a href="#最后玩儿一点小花样" class="headerlink" title="最后玩儿一点小花样"></a>最后玩儿一点小花样</h2><p>如果用LaTeX的话可以这么玩儿哈哈哈哈</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\documentclass[UTF8]&#123;ctexart&#125;</span><br><span class="line">\usepackage&#123;fontspec,txfonts,microtype,shapepar,xcolor&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">&#123;\kaishu \color&#123;red&#125; &#123;</span><br><span class="line">\heartpar&#123;yxx小朋友我真的超级喜欢你的！&#125;&#125;&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure>
<h2 id="特别感谢"><a href="#特别感谢" class="headerlink" title="特别感谢"></a>特别感谢</h2><p>yxx小朋友！</p>
]]></content>
      <categories>
        <category>小朋友和我</category>
      </categories>
      <tags>
        <tag>yxx&amp;sxh</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello yxx</title>
    <url>/2020/03/15/Hello-yxx/</url>
    <content><![CDATA[<p><strong>我遇见你啦</strong><br>虽然现在这个博客还很单调<br>但是我会把它变得丰富多彩的！<br><del>如果有时间的话（咕咕咕）</del></p>
]]></content>
      <categories>
        <category>小朋友和我</category>
      </categories>
      <tags>
        <tag>yxx&amp;sxh</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/03/03/Hello-World-0/</url>
    <content><![CDATA[<h1 id="hello-world！"><a href="#hello-world！" class="headerlink" title="hello world！"></a>hello world！</h1>]]></content>
      <tags>
        <tag>小涵！</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/03/03/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<a id="more"></a>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
